(tensorflow) viceroy\(__git_ps1) Image_Classification $ python cnn.py 
Using TensorFlow backend.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 32, 32, 4)         112       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 32, 4)         148       
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 32, 32, 4)         148       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 16, 16, 4)         0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 16, 16, 8)         296       
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 16, 16, 8)         584       
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 16, 16, 8)         584       
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 8, 8, 8)           0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 512)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 600)               615000    
=================================================================
Total params: 1,142,184
Trainable params: 1,142,184
Non-trainable params: 0
_________________________________________________________________
None
Train on 7624 samples, validate on 78 samples
Epoch 1/50
2018-12-17 08:06:17.143605: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
7624/7624 [==============================] - 8s 1ms/step - loss: 5.8716 - acc: 0.0459 - val_loss: 5.4444 - val_acc: 0.0000e+00
Epoch 2/50
7624/7624 [==============================] - 8s 1ms/step - loss: 5.0622 - acc: 0.1089 - val_loss: 4.8468 - val_acc: 0.1538
Epoch 3/50
7624/7624 [==============================] - 9s 1ms/step - loss: 4.5665 - acc: 0.2057 - val_loss: 4.0227 - val_acc: 0.1923
Epoch 4/50
7624/7624 [==============================] - 8s 1ms/step - loss: 4.0406 - acc: 0.2914 - val_loss: 3.7961 - val_acc: 0.3077
Epoch 5/50
7624/7624 [==============================] - 8s 1ms/step - loss: 3.4471 - acc: 0.3930 - val_loss: 2.9758 - val_acc: 0.4359
Epoch 6/50
7624/7624 [==============================] - 8s 1ms/step - loss: 2.9864 - acc: 0.4812 - val_loss: 2.6235 - val_acc: 0.5256
Epoch 7/50
7624/7624 [==============================] - 8s 1ms/step - loss: 2.6311 - acc: 0.5367 - val_loss: 2.3315 - val_acc: 0.5769
Epoch 8/50
7624/7624 [==============================] - 8s 1ms/step - loss: 2.2339 - acc: 0.6043 - val_loss: 2.1356 - val_acc: 0.6795
Epoch 9/50
7624/7624 [==============================] - 8s 1ms/step - loss: 1.9625 - acc: 0.6474 - val_loss: 1.8886 - val_acc: 0.6538
Epoch 10/50
7624/7624 [==============================] - 8s 1ms/step - loss: 1.7311 - acc: 0.6810 - val_loss: 2.3093 - val_acc: 0.6410
Epoch 11/50
7624/7624 [==============================] - 8s 1ms/step - loss: 1.5768 - acc: 0.7032 - val_loss: 1.6710 - val_acc: 0.7179
Epoch 12/50
7624/7624 [==============================] - 8s 1ms/step - loss: 1.3477 - acc: 0.7446 - val_loss: 1.8848 - val_acc: 0.7051
Epoch 13/50
7624/7624 [==============================] - 8s 1ms/step - loss: 1.1730 - acc: 0.7735 - val_loss: 1.8723 - val_acc: 0.6538
Epoch 14/50
7624/7624 [==============================] - 9s 1ms/step - loss: 1.0256 - acc: 0.7979 - val_loss: 1.6092 - val_acc: 0.7692
Epoch 15/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.9519 - acc: 0.7959 - val_loss: 1.4614 - val_acc: 0.7821
Epoch 16/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.8013 - acc: 0.8294 - val_loss: 1.3937 - val_acc: 0.7308
Epoch 17/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.6718 - acc: 0.8541 - val_loss: 1.6944 - val_acc: 0.7308
Epoch 18/50
7624/7624 [==============================] - 9s 1ms/step - loss: 0.6752 - acc: 0.8547 - val_loss: 1.4038 - val_acc: 0.7821
Epoch 19/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.4951 - acc: 0.8858 - val_loss: 1.6550 - val_acc: 0.7179
Epoch 20/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.4848 - acc: 0.8944 - val_loss: 1.6957 - val_acc: 0.7436
Epoch 21/50
7624/7624 [==============================] - 9s 1ms/step - loss: 0.4912 - acc: 0.8860 - val_loss: 1.6912 - val_acc: 0.7564
Epoch 22/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.3433 - acc: 0.9254 - val_loss: 1.7202 - val_acc: 0.7564
Epoch 23/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.2827 - acc: 0.9366 - val_loss: 1.4760 - val_acc: 0.8205
Epoch 24/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.3165 - acc: 0.9294 - val_loss: 1.6922 - val_acc: 0.7821
Epoch 25/50
7624/7624 [==============================] - 9s 1ms/step - loss: 0.2599 - acc: 0.9454 - val_loss: 1.5191 - val_acc: 0.8205
Epoch 26/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.2205 - acc: 0.9596 - val_loss: 1.5088 - val_acc: 0.7949
Epoch 27/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.1935 - acc: 0.9608 - val_loss: 1.6407 - val_acc: 0.7949
Epoch 28/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.1901 - acc: 0.9627 - val_loss: 1.5438 - val_acc: 0.7949
Epoch 29/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.1648 - acc: 0.9704 - val_loss: 1.7912 - val_acc: 0.8205
Epoch 30/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.1424 - acc: 0.9785 - val_loss: 1.6870 - val_acc: 0.8205
Epoch 31/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.1428 - acc: 0.9759 - val_loss: 1.9191 - val_acc: 0.7949
Epoch 32/50
7624/7624 [==============================] - 9s 1ms/step - loss: 0.1511 - acc: 0.9730 - val_loss: 1.6596 - val_acc: 0.8077
Epoch 33/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.1290 - acc: 0.9819 - val_loss: 1.5603 - val_acc: 0.8333
Epoch 34/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.1222 - acc: 0.9814 - val_loss: 1.8219 - val_acc: 0.8333
Epoch 35/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.1248 - acc: 0.9841 - val_loss: 1.7657 - val_acc: 0.7949
Epoch 36/50
7624/7624 [==============================] - 9s 1ms/step - loss: 0.1284 - acc: 0.9819 - val_loss: 1.7526 - val_acc: 0.7949
Epoch 37/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.1132 - acc: 0.9857 - val_loss: 1.6069 - val_acc: 0.8205
Epoch 38/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.1083 - acc: 0.9858 - val_loss: 1.6306 - val_acc: 0.7949
Epoch 39/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.1126 - acc: 0.9868 - val_loss: 1.6948 - val_acc: 0.8205
Epoch 40/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.1093 - acc: 0.9882 - val_loss: 1.6369 - val_acc: 0.8077
Epoch 41/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.1068 - acc: 0.9868 - val_loss: 1.8002 - val_acc: 0.7949
Epoch 42/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.1115 - acc: 0.9858 - val_loss: 1.6585 - val_acc: 0.8205
Epoch 43/50
7624/7624 [==============================] - 9s 1ms/step - loss: 0.1019 - acc: 0.9881 - val_loss: 1.6023 - val_acc: 0.8077
Epoch 44/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.1106 - acc: 0.9865 - val_loss: 1.6080 - val_acc: 0.8333
Epoch 45/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.1086 - acc: 0.9873 - val_loss: 1.6825 - val_acc: 0.8205
Epoch 46/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.0917 - acc: 0.9899 - val_loss: 1.7184 - val_acc: 0.8333
Epoch 47/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.1018 - acc: 0.9889 - val_loss: 1.6511 - val_acc: 0.8077
Epoch 48/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.0975 - acc: 0.9882 - val_loss: 1.8245 - val_acc: 0.7949
Epoch 49/50
7624/7624 [==============================] - 8s 1ms/step - loss: 0.1074 - acc: 0.9889 - val_loss: 1.7711 - val_acc: 0.8077
Epoch 50/50
7624/7624 [==============================] - 9s 1ms/step - loss: 0.0991 - acc: 0.9887 - val_loss: 1.6811 - val_acc: 0.8205
Saved model to disk

(tensorflow) viceroy\(__git_ps1) Image_Classification $ python prediction.py 
Using TensorFlow backend.
2018-12-17 08:18:52.314588: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Loaded model from disk
7702/7702 [==============================] - 4s 543us/step
loss: 12.04%
acc: 98.65%

